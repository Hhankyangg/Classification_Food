{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOOD IMAGE CLASSFICATION\n",
    "\n",
    "食物图片分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !unzip -q /content/drive/MyDrive/ML2022/food-11.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的导入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dataset` & `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_set = DatasetFolder(\"food-11/training/labeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n",
    "valid_set = DatasetFolder(\"food-11/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
    "unlabeled_set = DatasetFolder(\"food-11/training/unlabeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n",
    "test_set = DatasetFolder(\"food-11/testing\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 半监督"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoDataset(Dataset):\n",
    "    def __init__(self, dataset, indices, labels=[]):\n",
    "        self.dataset = dataset\n",
    "        self.indices= indices\n",
    "        self.targets = labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sub_set = self.dataset[self.indices[index]]\n",
    "        imgs, _ = sub_set\n",
    "        if len(self.targets) > 0:\n",
    "            return imgs, self.targets[index]\n",
    "        else:\n",
    "            return sub_set\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_labels(dataset, model, threshold, is_test=False):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Make sure the model is in eval mode.\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # Iterate over the dataset by batches.\n",
    "    pseudo_probs = []\n",
    "    pseudo_labels = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        img, _ = batch\n",
    "\n",
    "        # Forward the data\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(img.to(device))\n",
    "\n",
    "        # Obtain the probability distributions by applying softmax on logits.\n",
    "        probs = softmax(logits)\n",
    "        probs_max, preds = probs.max(1) # max return [probs], [batch_idx]\n",
    "\n",
    "        pseudo_probs.extend(probs_max.cpu().numpy().tolist())\n",
    "        pseudo_labels.extend(preds.cpu().numpy().tolist())\n",
    "        if is_test:\n",
    "            break\n",
    "    pseudo_indices = [i for i, v in enumerate(pseudo_probs) if v >= threshold]\n",
    "    pseudo_set = PseudoDataset(dataset, pseudo_indices, [pseudo_labels[i] for i in pseudo_indices])\n",
    "    # Turn off the eval mode.\n",
    "    model.train()\n",
    "    return pseudo_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = resnet50().to(device)\n",
    "model.device = device\n",
    "model.fc.out_features = 11\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, eta_min=1e-6, T_0=15)\n",
    "\n",
    "# The number of training epochs.\n",
    "n_epochs = 200\n",
    "\n",
    "# Pseudo\n",
    "threshold = 0.85\n",
    "pseudo_interval = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc = []\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # ---------- Pseudo ----------\n",
    "    if best_acc > 0.4 and epoch % pseudo_interval == 0:\n",
    "        pseudo_set = get_pseudo_labels(unlabeled_set, model, threshold=threshold)\n",
    "\n",
    "        concat_dataset = ConcatDataset([train_set, pseudo_set])\n",
    "        train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "    # ---------- Training ----------\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "\n",
    "    # Iterate the training set by batches.\n",
    "    for batch in tqdm(train_loader):\n",
    "\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # Forward the data. (Make sure data and model are on the same device.)\n",
    "        logits = model(imgs.to(device))\n",
    "\n",
    "        # Calculate the cross-entropy loss.\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the gradients for parameters.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the gradient norms for stable training.\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "\n",
    "        # Update the parameters with computed gradients.\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    model.eval()\n",
    "\n",
    "    # These are used to record information in validation.\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    # Iterate the validation set by batches.\n",
    "    for batch in tqdm(valid_loader):\n",
    "\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        # We can still compute the loss (but not the gradient).\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "    if len(final_acc) == 0 or valid_acc >= max(final_acc):\n",
    "        best_acc = valid_acc\n",
    "        print(f\"[ BEST Valid acc | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    final_acc.append(valid_acc)\n",
    "    torch.save(model.state_dict(), './model.pth')\n",
    "    torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (), but expected one of:\n * (int dim, torch.dtype dtype)\n * (name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         logits \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Take the class with greatest logit as prediction and record it.\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Save predictions into the file.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (), but expected one of:\n * (int dim, torch.dtype dtype)\n * (name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "with open(\"prediction.csv\", \"w\") as f:\n",
    "    f.write(\"Method,Acc\\n\")\n",
    "    f.write(f\"CNN whith resnet50,{best_acc:.3f}\\n\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    imgs, labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs.to(device))\n",
    "\n",
    "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "with open(\"predict.csv\", \"w\") as f:\n",
    "\n",
    "    f.write(\"Id,Category\\n\")\n",
    "    for i, pred in  enumerate(predictions):\n",
    "        f.write(f\"{i},{pred}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
