{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOOD IMAGE CLASSFICATION\n",
    "\n",
    "食物图片分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !unzip -q /content/drive/MyDrive/ML2022/food-11.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的导入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dataset` & `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_set = DatasetFolder(\"food-11/training/labeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n",
    "valid_set = DatasetFolder(\"food-11/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
    "test_set = DatasetFolder(\"food-11/testing\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # n = (W - kernel_size + 2 * padding) / stride + 1\n",
    "\n",
    "        # input image size: [3, 224, 224]\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4, 4, 0),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256 * 14 * 14, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input (x): [batch_size, 3, 224, 224]\n",
    "        # output: [batch_size, 11]\n",
    "\n",
    "        # Extract features by convolutional layers.\n",
    "        x = self.cnn_layers(x)\n",
    "\n",
    "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = Classifier().to(device)\n",
    "model.device = device\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, eta_min=1e-6, T_0=15)\n",
    "\n",
    "# The number of training epochs.\n",
    "n_epochs = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc = []\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # ---------- Training ----------\n",
    "    model.train()\n",
    "    \n",
    "    # These are used to record information in training.\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "\n",
    "    # Iterate the training set by batches.\n",
    "    for batch in tqdm(train_loader):\n",
    "\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # Forward the data. (Make sure data and model are on the same device.)\n",
    "        logits = model(imgs.to(device))\n",
    "\n",
    "        # Calculate the cross-entropy loss.\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the gradients for parameters.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the gradient norms for stable training.\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "\n",
    "        # Update the parameters with computed gradients.\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    model.eval()\n",
    "\n",
    "    # These are used to record information in validation.\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    # Iterate the validation set by batches.\n",
    "    for batch in tqdm(valid_loader):\n",
    "\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        # We can still compute the loss (but not the gradient).\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "    if len(final_acc) == 0 or valid_acc >= max(final_acc):\n",
    "        best_acc = valid_acc\n",
    "        print(f\"[ BEST Valid acc | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    final_acc.append(valid_acc)\n",
    "    torch.save(model.state_dict(), './model.pth')\n",
    "    torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prediction.csv\", \"w\") as f:\n",
    "    f.write(\"Method,Acc\\n\")\n",
    "    f.write(f\"CNN whith no supervised learning,{best_acc:.3f}\\n\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    imgs, labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs.to(device))\n",
    "\n",
    "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "with open(\"predict.csv\", \"w\") as f:\n",
    "\n",
    "    f.write(\"Id,Category\\n\")\n",
    "    for i, pred in  enumerate(predictions):\n",
    "        f.write(f\"{i},{pred}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
